{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Alexnet_Pytorch.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saikrithik/Jovian-Course-Pytorch-DeepLearning/blob/main/Alexnet_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-HePXK05f-0w",
        "outputId": "f5fe408b-1566-4675-c18e-e598b971362f"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Feb 19 08:13:32 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.39       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   64C    P8    11W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQsGoprKbl-D"
      },
      "source": [
        "from __future__ import print_function\r\n",
        "import torch"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmO7TRV-d2j_",
        "outputId": "cdedab75-853e-40d1-8351-810b2468571d"
      },
      "source": [
        "#empty gives unknown uniniliazed matrix,whatever values were allocated in the memory will appear as intial values\r\n",
        "#Here 5 and 4 represents number of rows and columns in the matrix\r\n",
        "#whatever values appeared first,so it doesnt work like rand\r\n",
        "a=torch.empty(5,4)\r\n",
        "print(a)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[2.0406e-35, 0.0000e+00, 7.0065e-44, 6.8664e-44],\n",
            "        [6.3058e-44, 6.7262e-44, 7.0065e-44, 6.3058e-44],\n",
            "        [6.8664e-44, 7.9874e-44, 1.1771e-43, 6.7262e-44],\n",
            "        [7.8473e-44, 8.1275e-44, 6.8664e-44, 7.1466e-44],\n",
            "        [8.1275e-44, 7.1466e-44, 7.7071e-44, 6.4460e-44]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWiJ8x1TfJOS",
        "outputId": "a4131c35-54fa-451e-cd8c-c650b6f07415"
      },
      "source": [
        "b=torch.rand(5,4)\r\n",
        "print(b)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.0516, 0.7948, 0.1267, 0.2477],\n",
            "        [0.4842, 0.5433, 0.7464, 0.1769],\n",
            "        [0.2408, 0.5702, 0.7308, 0.4321],\n",
            "        [0.5131, 0.9061, 0.6008, 0.3738],\n",
            "        [0.9793, 0.4127, 0.5426, 0.9798]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZrp_bU8fc0T",
        "outputId": "068866a3-6455-492a-d440-cfc59cafe168"
      },
      "source": [
        "c=torch.tensor([5,4])\r\n",
        "print(c)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([5, 4])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6VHmBs-qf1fO",
        "outputId": "3a93a927-69c9-425b-e5f9-aa28fd82fc9a"
      },
      "source": [
        "c=c.new_ones(5,4,dtype=torch.float)\r\n",
        "print(c)\r\n",
        "c=torch.randn_like(c,dtype=torch.float)\r\n",
        "print(c)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.]])\n",
            "tensor([[-0.9551,  0.1528,  1.9452,  0.7809],\n",
            "        [-1.8558, -0.5392,  0.3066,  0.3107],\n",
            "        [-1.3715,  2.4447, -0.4259,  0.4365],\n",
            "        [-0.7531, -0.4696,  1.9839, -1.2900],\n",
            "        [ 1.0509,  1.8174, -0.2245, -0.8999]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LqUOKklXgxM4",
        "outputId": "278d4eea-3969-4b37-c758-ec267d875ba2"
      },
      "source": [
        "d=torch.randn(5,4)\r\n",
        "print(torch.add(c,d))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-1.3065,  2.2575,  0.4315,  0.0348],\n",
            "        [-2.2813,  0.5915,  1.1162, -0.3149],\n",
            "        [-1.8640,  2.4961, -0.3316,  0.9469],\n",
            "        [-0.3835, -2.5115,  4.4687, -1.4774],\n",
            "        [ 1.7214,  0.5438, -2.5162, -0.4000]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90KTmdhrf2N9",
        "outputId": "37361809-8cc7-4985-d52c-e4a847916fbb"
      },
      "source": [
        "b=torch.empty(5,4)\r\n",
        "c=torch.empty(5,4)\r\n",
        "print(b)\r\n",
        "print(c)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[2.0407e-35, 0.0000e+00, 7.0065e-44, 6.8664e-44],\n",
            "        [6.3058e-44, 6.7262e-44, 7.0065e-44, 6.3058e-44],\n",
            "        [6.8664e-44, 7.9874e-44, 1.1771e-43, 6.7262e-44],\n",
            "        [7.8473e-44, 8.1275e-44, 6.8664e-44, 7.1466e-44],\n",
            "        [8.1275e-44, 7.2868e-44, 7.4269e-44, 6.4460e-44]])\n",
            "tensor([[2.0407e-35, 0.0000e+00, 1.2673e-01, 2.4771e-01],\n",
            "        [4.8415e-01, 5.4333e-01, 7.4645e-01, 1.7694e-01],\n",
            "        [2.4083e-01, 5.7024e-01, 7.3083e-01, 4.3208e-01],\n",
            "        [5.1312e-01, 9.0606e-01, 6.0083e-01, 3.7376e-01],\n",
            "        [9.7927e-01, 4.1266e-01, 5.4258e-01, 9.7981e-01]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-9tdVM_f2Pb",
        "outputId": "901c7ca4-253c-4681-fb3a-f17513fe2e0e"
      },
      "source": [
        "print(b.add(c))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[4.0814e-35, 0.0000e+00, 1.2673e-01, 2.4771e-01],\n",
            "        [4.8415e-01, 5.4333e-01, 7.4645e-01, 1.7694e-01],\n",
            "        [2.4083e-01, 5.7024e-01, 7.3083e-01, 4.3208e-01],\n",
            "        [5.1312e-01, 9.0606e-01, 6.0083e-01, 3.7376e-01],\n",
            "        [9.7927e-01, 4.1266e-01, 5.4258e-01, 9.7981e-01]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGxw5gZcqur-",
        "outputId": "3ec61805-4016-4dc2-d082-0c9b90c78be4"
      },
      "source": [
        "if torch.cuda.is_available():\r\n",
        "  device=torch.device(\"cuda\") #a cuda object\r\n",
        "  y=torch.ones_like(c,device=device)  #directly create a tensor on gpu\r\n",
        "  c=c.to(device)    #move the tensor to gpu\r\n",
        "  z=y+c\r\n",
        "  print(z)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1.0000, 1.0000, 1.1267, 1.2477],\n",
            "        [1.4842, 1.5433, 1.7464, 1.1769],\n",
            "        [1.2408, 1.5702, 1.7308, 1.4321],\n",
            "        [1.5131, 1.9061, 1.6008, 1.3738],\n",
            "        [1.9793, 1.4127, 1.5426, 1.9798]], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7-MrlNwWqc5",
        "outputId": "81162fd8-b631-46bd-d4fd-6c3f4ce095e5"
      },
      "source": [
        "device"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jsYL9LtuhAM"
      },
      "source": [
        "# Alexnet neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZWE0nsTupBg",
        "outputId": "427c8a0e-f6e0-420d-d351-3ea527eca7c9"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "from torchsummary import summary\r\n",
        "#-----------Change This according to ur req---------------\r\n",
        "out_classes = 3\r\n",
        "#---------------------------------------------------------\r\n",
        "\r\n",
        "def conv_block(in_channels, out_channels,kernel=3,s=1,p=1, pool=False):\r\n",
        "    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=kernel,stride=s,padding=p), \r\n",
        "              nn.BatchNorm2d(out_channels), \r\n",
        "              nn.ReLU(inplace=True)]\r\n",
        "    if pool: layers.append(nn.MaxPool2d(2))\r\n",
        "    return nn.Sequential(*layers)\r\n",
        "\r\n",
        "class neural_network(nn.Module):\r\n",
        "\r\n",
        "  def __init__(self):\r\n",
        "    super(neural_network,self).__init__()\r\n",
        "    #3,224,224\r\n",
        "    self.conv1 = conv_block(3, 96,kernel=11,s=4,p=1,pool=True) #96,54,54 --> #96,27,27\r\n",
        "    self.conv2 = conv_block(96, 256,kernel=5,s=1,p=2,pool=True) #256,27,27 --> #256,13,13\r\n",
        "    self.conv3= conv_block(256,384,kernel=3,s=1,p=1)#384,13,13\r\n",
        "    self.conv4= conv_block(384,384,kernel=3,s=1,p=1)#384,13,13\r\n",
        "    self.conv5= conv_block(384, 256,kernel=3,s=1,p=1,pool=True)#256,6,6\r\n",
        "    self.flatten = nn.Flatten()#256*6*6\r\n",
        "    self.drop = nn.Dropout(0.5)\r\n",
        "    self.fc1=nn.Linear(256*6*6,4096)\r\n",
        "    self.fc2=nn.Linear(4096,1000)\r\n",
        "    self.fc3=nn.Linear(1000,out_classes)\r\n",
        "    self.soft=nn.Softmax(dim=1)\r\n",
        "\r\n",
        "  def forward(self,x):\r\n",
        "    out = self.conv1(x)\r\n",
        "    out = self.conv2(out)\r\n",
        "    out = self.conv3(out)\r\n",
        "    out = self.conv4(out)\r\n",
        "    out = self.conv5(out)\r\n",
        "    out = self.flatten(out)\r\n",
        "    out = self.drop(out)\r\n",
        "    out = self.fc1(out)\r\n",
        "    out = self.fc2(out)\r\n",
        "    out = self.fc3(out)\r\n",
        "    out = self.soft(out)\r\n",
        "    \r\n",
        "    # x=nn.BatchNorm2d(x)\r\n",
        "    # x=F.max_pool2d(F.relu(self.conv2(x)),(3,3),stride=2)\r\n",
        "    # x=nn.BatchNorm2d(self.conv3(x))\r\n",
        "    # x=nn.BatchNorm2d(self.conv4(x))\r\n",
        "    # x=F.max_pool2d(F.relu(self.conv5(x)),(3,3),stride=2)\r\n",
        "    # x=F.dropout(x,p=0.5)\r\n",
        "    # x=x.view(x.size()[0],-1)\r\n",
        "    # x=F.relu(self.fc1(x))\r\n",
        "    # x=F.dropout(x,p=0.5)\r\n",
        "    # x=F.relu(self.fc2(x))\r\n",
        "    # x=self.fc3(x)\r\n",
        "    return out\r\n",
        "\r\n",
        "x = torch.randn(1,1,32,32)\r\n",
        "model=neural_network()\r\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\r\n",
        "\r\n",
        "x=torch.FloatTensor(x).to(device)\r\n",
        "model=model.to(device)\r\n",
        "summary(model,(3,224,224))\r\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 96, 54, 54]          34,944\n",
            "       BatchNorm2d-2           [-1, 96, 54, 54]             192\n",
            "              ReLU-3           [-1, 96, 54, 54]               0\n",
            "         MaxPool2d-4           [-1, 96, 27, 27]               0\n",
            "            Conv2d-5          [-1, 256, 27, 27]         614,656\n",
            "       BatchNorm2d-6          [-1, 256, 27, 27]             512\n",
            "              ReLU-7          [-1, 256, 27, 27]               0\n",
            "         MaxPool2d-8          [-1, 256, 13, 13]               0\n",
            "            Conv2d-9          [-1, 384, 13, 13]         885,120\n",
            "      BatchNorm2d-10          [-1, 384, 13, 13]             768\n",
            "             ReLU-11          [-1, 384, 13, 13]               0\n",
            "           Conv2d-12          [-1, 384, 13, 13]       1,327,488\n",
            "      BatchNorm2d-13          [-1, 384, 13, 13]             768\n",
            "             ReLU-14          [-1, 384, 13, 13]               0\n",
            "           Conv2d-15          [-1, 256, 13, 13]         884,992\n",
            "      BatchNorm2d-16          [-1, 256, 13, 13]             512\n",
            "             ReLU-17          [-1, 256, 13, 13]               0\n",
            "        MaxPool2d-18            [-1, 256, 6, 6]               0\n",
            "          Flatten-19                 [-1, 9216]               0\n",
            "          Dropout-20                 [-1, 9216]               0\n",
            "           Linear-21                 [-1, 4096]      37,752,832\n",
            "           Linear-22                 [-1, 1000]       4,097,000\n",
            "           Linear-23                    [-1, 3]           3,003\n",
            "          Softmax-24                    [-1, 3]               0\n",
            "================================================================\n",
            "Total params: 45,602,787\n",
            "Trainable params: 45,602,787\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 15.75\n",
            "Params size (MB): 173.96\n",
            "Estimated Total Size (MB): 190.29\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vt8ryTpc9vMh"
      },
      "source": [
        ""
      ],
      "execution_count": 28,
      "outputs": []
    }
  ]
}